{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f74b1b",
   "metadata": {},
   "source": [
    "# Generate images\n",
    "\n",
    "The Gemini API supports image generation using Gemini 2.0 Flash Experimental and using Imagen 3. This guide helps you get started with both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815ed947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "contents = ('Hi, can you create a 3d rendered image of a pig '\n",
    "            'with wings and a top hat flying over a happy '\n",
    "            'futuristic scifi city with lots of greenery?')\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp-image-generation\",\n",
    "    contents=contents,\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['Text', 'Image']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO((part.inline_data.data)))\n",
    "    image.save('data/gemini-native-image.png')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072978a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "contents = (\"Generate me a Image for UML daigram in a flowchat style that shows the following\",\n",
    "            \"1. User enters a prompt in the chat window\\n\"\n",
    "            \"2. The system processes the prompt\\n\"\n",
    "            \"3. The system generates a response\\n\"\n",
    "            \"4. The user receives the response in the chat window\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp-image-generation\",\n",
    "    contents=contents,\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['Text', 'Image']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO((part.inline_data.data)))\n",
    "    image.save('data/uml.png')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3139c2",
   "metadata": {},
   "source": [
    "## Image editing with Gemini\n",
    "To perform image editing, add an image as input. The following example demonstrats uploading base64 encoded images. For multiple images and larger payloads, check the image input section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44fc0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "image = PIL.Image.open('data/gemini-native-image.png')\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "text_input = ('Hi, This is a pig image'\n",
    "            'Can you add a llama next to me?',)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-exp-image-generation\",\n",
    "    contents=[text_input, image],\n",
    "    config=types.GenerateContentConfig(\n",
    "      response_modalities=['Text', 'Image']\n",
    "    )\n",
    ")\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "  if part.text is not None:\n",
    "    print(part.text)\n",
    "  elif part.inline_data is not None:\n",
    "    image = Image.open(BytesIO(part.inline_data.data))\n",
    "    image.save('data/updated_image.png')\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce61e72",
   "metadata": {},
   "source": [
    "## Generate images using Imagen 3\n",
    "The Gemini API provides access to Imagen 3, Google's highest quality text-to-image model, featuring a number of new and improved capabilities. Imagen 3 can do the following:\n",
    "\n",
    "- Generate images with better detail, richer lighting, and fewer distracting artifacts than previous models\n",
    "- Understand prompts written in natural language\n",
    "- Generate images in a wide range of formats and styles\n",
    "- Render text more effectively than previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5d389",
   "metadata": {},
   "source": [
    "**Note: Imagen 3 is only available on the Paid Tier and always includes a SynthID watermark.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "client = genai.Client(api_key='GEMINI_API_KEY')\n",
    "\n",
    "response = client.models.generate_images(\n",
    "    model='imagen-3.0-generate-002',\n",
    "    prompt='Robot holding a red skateboard',\n",
    "    config=types.GenerateImagesConfig(\n",
    "        number_of_images= 4,\n",
    "    )\n",
    ")\n",
    "for generated_image in response.generated_images:\n",
    "  image = Image.open(BytesIO(generated_image.image.image_bytes))\n",
    "  image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f655fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac81eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
