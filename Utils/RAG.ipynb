{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946616d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31facce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ( AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline, )\n",
    "from langchain import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for laoding 4-bit quantized model\n",
    "def load_quantized_model(model_name:str):\n",
    "  \"\"\"\n",
    "  model_name: Name or path of the model to be loaded.\n",
    "  return: Loaded quantized model.\n",
    "  \"\"\"\n",
    "  bnb_config = BitsAndBytesConfig(\n",
    "      load_in_4bit=True,\n",
    "      bnb_4bit_use_double_quant=True,\n",
    "      bnb_4bit_quant_type=\"nf4\",\n",
    "      bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "  )\n",
    "  model = AutoModelForCausalLM.from_pretrained(\n",
    "      model_name,\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      quantization_config=bnb_config,\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c375698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing tokenizer\n",
    "def initialize_tokenizer(model_name:str):\n",
    "  \"\"\"\n",
    "  model_name: Name or path of the model to be loaded.\n",
    "  return: Tokenizer for the model.\n",
    "  \"\"\"\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_name, return_token_type_ids=False)\n",
    "  tokenizer.bos_token_id = 1 # Set beginning of sentence token id\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a426e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = initialize_tokenizer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_quantized_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
