{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKPK-_pj-BE3"
      },
      "source": [
        "# Simple RAG (Retrieval-Augmented Generation) System\n",
        "\n",
        "## Overview\n",
        "\n",
        "This code implements a basic Retrieval-Augmented Generation (RAG) system for processing and querying PDF documents. The system encodes the document content into a vector store, which can then be queried to retrieve relevant information.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. PDF processing and text extraction\n",
        "2. Text chunking for manageable processing\n",
        "3. Vector store creation using [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) and OpenAI embeddings\n",
        "4. Retriever setup for querying the processed documents\n",
        "5. Evaluation of the RAG system\n",
        "\n",
        "## Method Details\n",
        "\n",
        "### Document Preprocessing\n",
        "\n",
        "1. The PDF is loaded using PyPDFLoader.\n",
        "2. The text is split into chunks using RecursiveCharacterTextSplitter with specified chunk size and overlap.\n",
        "\n",
        "### Text Cleaning\n",
        "\n",
        "A custom function `replace_t_with_space` is applied to clean the text chunks. This likely addresses specific formatting issues in the PDF.\n",
        "\n",
        "### Vector Store Creation\n",
        "\n",
        "1. OpenAI embeddings are used to create vector representations of the text chunks.\n",
        "2. A FAISS vector store is created from these embeddings for efficient similarity search.\n",
        "\n",
        "### Retriever Setup\n",
        "\n",
        "1. A retriever is configured to fetch the top 2 most relevant chunks for a given query.\n",
        "\n",
        "### Encoding Function\n",
        "\n",
        "The `encode_pdf` function encapsulates the entire process of loading, chunking, cleaning, and encoding the PDF into a vector store.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "1. Modular Design: The encoding process is encapsulated in a single function for easy reuse.\n",
        "2. Configurable Chunking: Allows adjustment of chunk size and overlap.\n",
        "3. Efficient Retrieval: Uses FAISS for fast similarity search.\n",
        "4. Evaluation: Includes a function to evaluate the RAG system's performance.\n",
        "\n",
        "## Usage Example\n",
        "\n",
        "The code includes a test query: \"What is the main cause of climate change?\". This demonstrates how to use the retriever to fetch relevant context from the processed document.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "The system includes an `evaluate_rag` function to assess the performance of the retriever, though the specific metrics used are not detailed in the provided code.\n",
        "\n",
        "## Benefits of this Approach\n",
        "\n",
        "1. Scalability: Can handle large documents by processing them in chunks.\n",
        "2. Flexibility: Easy to adjust parameters like chunk size and number of retrieved results.\n",
        "3. Efficiency: Utilizes FAISS for fast similarity search in high-dimensional spaces.\n",
        "4. Integration with Advanced NLP: Uses OpenAI embeddings for state-of-the-art text representation.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This simple RAG system provides a solid foundation for building more complex information retrieval and question-answering systems. By encoding document content into a searchable vector store, it enables efficient retrieval of relevant information in response to queries. This approach is particularly useful for applications requiring quick access to specific information within large documents or document collections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvUHveE5-BE3"
      },
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVaHWFwh-BE4",
        "outputId": "d725de55-3b6e-45ad-a599-ca0f4e7d1698"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q pypdf\n",
        "!pip install -q PyMuPDF\n",
        "!pip install -q python-dotenv\n",
        "!pip install -q langchain-community\n",
        "!pip install -q langchain_google_genai\n",
        "!pip install -q rank_bm25\n",
        "!pip install -q faiss-cpu\n",
        "!pip install -q deepeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Rahul-Github\\\\Daily-Task\\\\all_rag_techniques'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(\"..\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.deepeval',\n",
              " '.python-version',\n",
              " '.venv',\n",
              " 'data',\n",
              " 'evaluation',\n",
              " 'evalute_rag.py',\n",
              " 'helper_functions.py',\n",
              " 'notebook',\n",
              " 'pyproject.toml',\n",
              " 'README.md',\n",
              " 'test.py',\n",
              " 'uv.lock',\n",
              " '__pycache__']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Original path append replaced for Colab compatibility\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from helper_functions import (\n",
        "    EmbeddingProvider, \n",
        "    retrieve_context_per_question, \n",
        "    replace_t_with_space, \n",
        "    get_langchain_embedding_provider, \n",
        "    show_context\n",
        ")\n",
        "\n",
        "# Import the new free evaluation functions\n",
        "from evalute_rag import simple_rag_evaluation, get_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KF5O4Wk4-BE6"
      },
      "outputs": [],
      "source": [
        "path = \"data/Understanding_Climate_Change.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0MAcEpU-BE6"
      },
      "source": [
        "### Encode document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "38suL-tJ-BE7"
      },
      "outputs": [],
      "source": [
        "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"\n",
        "    Encodes a PDF book into a vector store using Gemini embeddings.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the PDF file.\n",
        "        chunk_size: The desired size of each text chunk.\n",
        "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        A FAISS vector store containing the encoded book content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load PDF documents\n",
        "    loader = PyPDFLoader(path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
        "    )\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "    cleaned_texts = replace_t_with_space(texts)\n",
        "\n",
        "    # Create embeddings (Tested with Gemini and Amazon Bedrock)\n",
        "    embeddings = get_langchain_embedding_provider(EmbeddingProvider.GOOGLE_GENAI)\n",
        "    #embeddings = get_langchain_embedding_provider(EmbeddingProvider.AMAZON_BEDROCK)\n",
        "\n",
        "    # Create vector store\n",
        "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
        "\n",
        "    return vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8aysEXUh-BE7"
      },
      "outputs": [],
      "source": [
        "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaCrjGRA-BE7"
      },
      "source": [
        "### Create retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wgVN3-y1-BE7"
      },
      "outputs": [],
      "source": [
        "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQJUmIXS-BE7"
      },
      "source": [
        "### Test retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC9jmnHM-BE7",
        "outputId": "463219f6-d06c-4031-d348-f89a66ea15c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context 1:\n",
            "Understanding Climate Change \n",
            "Chapter 1: Introduction to Climate Change \n",
            "Climate change refers to significant, long-term changes in the global climate. The term \n",
            "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
            "precipitation, and wind patterns, over an extended period. Over the past century, human \n",
            "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
            "contributed to climate change. \n",
            "Historical Context \n",
            "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
            "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
            "11,700 years ago marking the beginning of the modern climate era and human civilization. \n",
            "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
            "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
            "\n",
            "\n",
            "Context 2:\n",
            "Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
            "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
            "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
            "activities have intensified this natural process, leading to a warmer climate. \n",
            "Fossil Fuels \n",
            "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
            "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
            "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
            "today. \n",
            "Coal\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_query = \"What is the main cause of climate change?\"\n",
        "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
        "show_context(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Simple RAG Evaluation with Free Models ===\n",
            "\n",
            "Evaluation Results:\n",
            "Question: What is the main cause of climate change?\n",
            "Documents Retrieved: 2\n",
            "Context Length: 1749 characters\n",
            "Relevance Score: 1.00/1.0\n",
            "Model Used: gemini\n",
            "\n",
            "Context Preview:\n",
            "Understanding Climate Change \n",
            "Chapter 1: Introduction to Climate Change \n",
            "Climate change refers to significant, long-term changes in the global climate. The term \n",
            "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
            "precipitation, and wind patterns, over an exte...\n",
            "\n",
            "Evaluation Results:\n",
            "Question: What is the main cause of climate change?\n",
            "Documents Retrieved: 2\n",
            "Context Length: 1749 characters\n",
            "Relevance Score: 1.00/1.0\n",
            "Model Used: gemini\n",
            "\n",
            "Context Preview:\n",
            "Understanding Climate Change \n",
            "Chapter 1: Introduction to Climate Change \n",
            "Climate change refers to significant, long-term changes in the global climate. The term \n",
            "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
            "precipitation, and wind patterns, over an exte...\n"
          ]
        }
      ],
      "source": [
        "# Simple RAG evaluation using free models\n",
        "print(\"=== Simple RAG Evaluation with Free Models ===\")\n",
        "result = simple_rag_evaluation(\n",
        "    retriever=chunks_query_retriever,\n",
        "    test_question=\"What is the main cause of climate change?\",\n",
        "    llm_provider=\"gemini\"  # Using free Google Gemini\n",
        ")\n",
        "\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Question: {result['question']}\")\n",
        "print(f\"Documents Retrieved: {result['num_docs_retrieved']}\")\n",
        "print(f\"Context Length: {result['context_length']} characters\")\n",
        "print(f\"Relevance Score: {result['relevance_score']:.2f}/1.0\")\n",
        "print(f\"Model Used: {result['model_used']}\")\n",
        "\n",
        "print(\"\\nContext Preview:\")\n",
        "print(result['context_preview'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Alternative Free Models for Evaluation ===\n",
            "\n",
            "Testing multiple questions with free Gemini model:\n",
            "\n",
            "1. Testing: What are greenhouse gases?\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "2. Testing: How does deforestation contribute to climate change?\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "2. Testing: How does deforestation contribute to climate change?\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "3. Testing: What are renewable energy sources?\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "3. Testing: What are renewable energy sources?\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "==================================================\n",
            "Free Model Options Available:\n",
            "1. Google Gemini (gemini-2.0-flash) - Default, requires GOOGLE_API_KEY\n",
            "2. Ollama (local models) - Completely free and local\n",
            "3. Groq (fast inference) - Free tier available\n",
            "\n",
            "To use different models, install:\n",
            "- Ollama: pip install langchain-ollama\n",
            "- Groq: pip install langchain-groq\n",
            "   Relevance Score: 1.00\n",
            "   Documents Retrieved: 2\n",
            "\n",
            "==================================================\n",
            "Free Model Options Available:\n",
            "1. Google Gemini (gemini-2.0-flash) - Default, requires GOOGLE_API_KEY\n",
            "2. Ollama (local models) - Completely free and local\n",
            "3. Groq (fast inference) - Free tier available\n",
            "\n",
            "To use different models, install:\n",
            "- Ollama: pip install langchain-ollama\n",
            "- Groq: pip install langchain-groq\n"
          ]
        }
      ],
      "source": [
        "# Alternative free evaluation options\n",
        "print(\"=== Alternative Free Models for Evaluation ===\")\n",
        "\n",
        "# Test different questions\n",
        "test_questions = [\n",
        "    \"What are greenhouse gases?\",\n",
        "    \"How does deforestation contribute to climate change?\",\n",
        "    \"What are renewable energy sources?\"\n",
        "]\n",
        "\n",
        "print(\"\\nTesting multiple questions with free Gemini model:\")\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n{i}. Testing: {question}\")\n",
        "    try:\n",
        "        result = simple_rag_evaluation(\n",
        "            retriever=chunks_query_retriever,\n",
        "            test_question=question,\n",
        "            llm_provider=\"gemini\"\n",
        "        )\n",
        "        print(f\"   Relevance Score: {result['relevance_score']:.2f}\")\n",
        "        print(f\"   Documents Retrieved: {result['num_docs_retrieved']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Free Model Options Available:\")\n",
        "print(\"1. Google Gemini (gemini-2.0-flash) - Default, requires GOOGLE_API_KEY\")\n",
        "print(\"2. Ollama (local models) - Completely free and local\")\n",
        "print(\"3. Groq (fast inference) - Free tier available\")\n",
        "print(\"\\nTo use different models, install:\")\n",
        "print(\"- Ollama: pip install langchain-ollama\")\n",
        "print(\"- Groq: pip install langchain-groq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Advanced Evaluation with Custom Functions ===\n",
            "Question: What are the main greenhouse gases?\n",
            "Generated Answer: According to the text, the main greenhouse gases are carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O).\n",
            "Expected Answer: The main greenhouse gases are carbon dioxide, methane, nitrous oxide, and fluorinated gases.\n",
            "Question: What are the main greenhouse gases?\n",
            "Generated Answer: According to the text, the main greenhouse gases are carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O).\n",
            "Expected Answer: The main greenhouse gases are carbon dioxide, methane, nitrous oxide, and fluorinated gases.\n",
            "\n",
            "Evaluation Scores:\n",
            "Relevance (context to question): 1.00\n",
            "Faithfulness (answer to context): 1.00\n",
            "\n",
            "Context Preview: Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2)...\n",
            "\n",
            "Evaluation Scores:\n",
            "Relevance (context to question): 1.00\n",
            "Faithfulness (answer to context): 1.00\n",
            "\n",
            "Context Preview: Chapter 2: Causes of Climate Change \n",
            "Greenhouse Gases \n",
            "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
            "atmosphere. Greenhouse gases, such as carbon dioxide (CO2)...\n"
          ]
        }
      ],
      "source": [
        "# Advanced evaluation with custom functions\n",
        "from evalute_rag import evaluate_test_cases, evaluate_relevance, evaluate_faithfulness\n",
        "\n",
        "print(\"=== Advanced Evaluation with Custom Functions ===\")\n",
        "\n",
        "# Example test case\n",
        "test_question = \"What are the main greenhouse gases?\"\n",
        "expected_answer = \"The main greenhouse gases are carbon dioxide, methane, nitrous oxide, and fluorinated gases.\"\n",
        "\n",
        "# Get context from retriever\n",
        "context_docs = chunks_query_retriever.get_relevant_documents(test_question)\n",
        "context = \"\\n\".join([doc.page_content for doc in context_docs])\n",
        "\n",
        "# Generate an answer using our helper functions\n",
        "llm = get_llm(\"gemini\")\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
        "Based on the following context, answer the question:\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\")\n",
        "\n",
        "answer_chain = answer_prompt | llm | StrOutputParser()\n",
        "generated_answer = answer_chain.invoke({\"context\": context, \"question\": test_question})\n",
        "\n",
        "print(f\"Question: {test_question}\")\n",
        "print(f\"Generated Answer: {generated_answer}\")\n",
        "print(f\"Expected Answer: {expected_answer}\")\n",
        "\n",
        "# Evaluate using custom functions\n",
        "relevance_score = evaluate_relevance(test_question, context, llm)\n",
        "faithfulness_score = evaluate_faithfulness(generated_answer, context, llm)\n",
        "\n",
        "print(f\"\\nEvaluation Scores:\")\n",
        "print(f\"Relevance (context to question): {relevance_score:.2f}\")\n",
        "print(f\"Faithfulness (answer to context): {faithfulness_score:.2f}\")\n",
        "\n",
        "print(f\"\\nContext Preview: {context[:200]}...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "all_rag_techniques",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
